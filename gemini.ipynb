{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2023913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amrit\\anaconda3\\envs\\IITH\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchmetrics\n",
    "from PIL import Image\n",
    "import os\n",
    "# from albumentations import Compose, ... # Import augmentations from albumentations\n",
    "# from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f617d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amrit\\anaconda3\\envs\\IITH\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Amrit\\anaconda3\\envs\\IITH\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification model...\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Classification Dataset ---\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                self.image_paths.append(os.path.join(class_path, img_name))\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB') # Ensure consistent color channels\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --- 2. Segmentation Dataset ---\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_files = sorted([f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg'))])\n",
    "        self.mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith(('.png', '.tif'))]) # Adjust mask extensions\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L') # Assuming single channel mask\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=np.array(image), mask=np.array(mask))\n",
    "            image = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "\n",
    "        return image, mask / 255.0 # Normalize mask to [0, 1] if needed\n",
    "\n",
    "# --- 3. Classification Model Training ---\n",
    "def train_classification_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step(val_loss) # For ReduceLROnPlateau\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=len(dataset.classes)).to(device)\n",
    "        print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}, Val Acc: {accuracy(torch.tensor(all_preds).to(device), torch.tensor(all_labels).to(device)):.4f}')\n",
    "    return model\n",
    "\n",
    "# --- 4. Segmentation Model Fine-tuning ---\n",
    "def train_segmentation_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, masks in train_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).unsqueeze(1) # Assuming binary masks, adjust for multi-class\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step(val_loss) # For ReduceLROnPlateau\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        dice_metric = torchmetrics.Dice(num_classes=1 if num_classes == 2 else num_classes, average='macro').to(device)\n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device).unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                # Assuming outputs are logits, apply sigmoid if using BCEWithLogitsLoss\n",
    "                if isinstance(criterion, nn.BCEWithLogitsLoss):\n",
    "                    preds = torch.sigmoid(outputs) > 0.5\n",
    "                else:\n",
    "                    preds = torch.argmax(outputs, dim=1) # For CrossEntropy or similar\n",
    "\n",
    "                # Ensure masks are in the correct format for metrics\n",
    "                dice_metric.update(preds, masks.squeeze(1).long()) # Adjust dimensions as needed\n",
    "                iou_metric.update(preds, masks.squeeze(1).long())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_dice = dice_metric.compute()\n",
    "        val_iou = iou_metric.compute()\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}, Val IoU: {val_iou:.4f}')\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(val_loss)\n",
    "        elif scheduler is not None:\n",
    "            scheduler.step()\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Hyperparameters and Setup ---\n",
    "    classification_data_dir = 'RetinalOCT_Dataset' # <--- CHANGE THIS\n",
    "    segmentation_img_dir = 'Segementation data/images'   # <--- CHANGE THIS\n",
    "    segmentation_mask_dir = 'Segementation data/masks'     # <--- CHANGE THIS\n",
    "    batch_size = 32\n",
    "    learning_rate_classification = 1e-3\n",
    "    learning_rate_segmentation = 1e-4\n",
    "    num_epochs_classification = 10\n",
    "    num_epochs_segmentation = 20\n",
    "    weight_decay = 1e-4\n",
    "    num_segmentation_classes = 8 + 1 # Number of disease classes + background (if applicable) <--- CHANGE THIS\n",
    "\n",
    "    # Check for CUDA availability\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- 1. Classification DataLoaders ---\n",
    "    classification_transform_train = T.Compose([\n",
    "        T.RandomResizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet stats\n",
    "    ])\n",
    "    classification_transform_val = T.Compose([\n",
    "        T.Resize(256),\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = ClassificationDataset(root_dir=os.path.join(classification_data_dir, 'train'), transform=classification_transform_train)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader_classification = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader_classification = DataLoader(val_dataset, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "    # --- 2. Initialize Classification Model and Train ---\n",
    "    classification_model = models.resnet50(pretrained=True) # Or any other chosen architecture\n",
    "    num_classes = len(dataset.classes)\n",
    "    classification_model.fc = nn.Linear(classification_model.fc.in_features, num_classes)\n",
    "    classification_model.to(device)\n",
    "\n",
    "    criterion_classification = nn.CrossEntropyLoss()\n",
    "    optimizer_classification = optim.AdamW(classification_model.parameters(), lr=learning_rate_classification, weight_decay=weight_decay)\n",
    "    scheduler_classification = ReduceLROnPlateau(optimizer_classification, mode='min', patience=3, factor=0.1)\n",
    "\n",
    "    print(\"Training classification model...\")\n",
    "\n",
    "    trained_classification_model = train_classification_model(\n",
    "        classification_model, train_loader_classification, val_loader_classification,\n",
    "        criterion_classification, optimizer_classification, scheduler_classification,\n",
    "        num_epochs_classification, device\n",
    "    )\n",
    "\n",
    "    # Save the trained classification model weights\n",
    "    torch.save(trained_classification_model.state_dict(), 'pretrained_classification_model.pth')\n",
    "\n",
    "    print(\"Classification model training complete.\")\n",
    "\n",
    "    # --- 3. Segmentation DataLoaders ---\n",
    "    segmentation_transform_train = None # Define your segmentation augmentations using torchvision or albumentations <--- CHANGE THIS\n",
    "    segmentation_transform_val = None   # Define your segmentation validation augmentations <--- CHANGE THIS\n",
    "\n",
    "    masked_dataset = SegmentationDataset(\n",
    "        img_dir=segmentation_img_dir,\n",
    "        mask_dir=segmentation_mask_dir,\n",
    "        transform=segmentation_transform_train # Apply augmentations here if using albumentations\n",
    "    )\n",
    "\n",
    "    print(\"Training segmentation model...\")\n",
    "\n",
    "    train_size_segmentation = int(0.8 * len(masked_dataset))\n",
    "    val_size_segmentation = len(masked_dataset) - train_size_segmentation\n",
    "    train_dataset_segmentation, val_dataset_segmentation = random_split(masked_dataset, [train_size_segmentation, val_size_segmentation], generator=torch.Generator().manual_seed(42))\n",
    "    train_loader_segmentation = DataLoader(train_dataset_segmentation, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader_segmentation = DataLoader(val_dataset_segmentation, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "    # --- 4. Initialize Segmentation Model and Fine-tune ---\n",
    "    # Example using segmentation_models_pytorch U-Net with ResNet50 encoder\n",
    "    segmentation_model = smp.Unet(\n",
    "        encoder_name=\"resnet50\",\n",
    "        encoder_weights=None, # We will load our pretrained weights\n",
    "        in_channels=3,\n",
    "        classes=num_segmentation_classes\n",
    "    )\n",
    "\n",
    "    print(\"Loading pretrained classification model weights...\")\n",
    "\n",
    "    # Load pretrained weights into the encoder\n",
    "    pretrained_dict = torch.load('pretrained_classification_model.pth')\n",
    "    model_dict = segmentation_model.encoder.state_dict()\n",
    "\n",
    "    # Filter out unnecessary keys (e.g., fc layer weights)\n",
    "    pretrained_dict_filtered = {k: v for k, v in pretrained_dict.items() if k in model_dict and v.size() == model_dict[k].size()}\n",
    "    model_dict.update(pretrained_dict_filtered)\n",
    "    segmentation_model.encoder.load_state_dict(model_dict, strict=False)\n",
    "\n",
    "    # Freeze encoder layers (optional, can also fine-tune with a smaller lr)\n",
    "    for name, param in segmentation_model.encoder.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    segmentation_model.to(device)\n",
    "\n",
    "    # Define segmentation loss and optimizer\n",
    "    criterion_segmentation = nn.CrossEntropyLoss() if num_segmentation_classes > 1 else nn.BCEWithLogitsLoss() # <--- ADJUST LOSS BASED ON TASK\n",
    "    optimizer_segmentation = optim.AdamW(segmentation_model.parameters(), lr=learning_rate_segmentation, weight_decay=weight_decay)\n",
    "    scheduler_segmentation = ReduceLROnPlateau(optimizer_segmentation, mode='min', patience=5, factor=0.1)\n",
    "\n",
    "    print(\"Training segmentation model...\")\n",
    "\n",
    "    # Train the segmentation model\n",
    "    trained_segmentation_model = train_segmentation_model(\n",
    "        segmentation_model, train_loader_segmentation, val_loader_segmentation,\n",
    "        criterion_segmentation, optimizer_segmentation, scheduler_segmentation,\n",
    "        num_epochs_segmentation, device, num_segmentation_classes\n",
    "    )\n",
    "\n",
    "    # Save the trained segmentation model\n",
    "    torch.save(trained_segmentation_model.state_dict(), 'trained_segmentation_model.pth')\n",
    "\n",
    "    print(\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IITH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
